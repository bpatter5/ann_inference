{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Inference Notebook\n",
    "\n",
    "Examples on how to use the `ann_inference` package to gain a deeper understanding of neural networks. To begin I'll load the `arrow_helper.py` file into memory so I can use a few of the builtin methods to work with `Parquet` tables that have been written to disk on my system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import  ann_inference.data.arrow_helper as ah\n",
    "import ann_inference.sample.boot as boot\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterations of a simple feedforward neural network were run and the column averages of the model weights were computed over each epoch. The Apache `Arrow` project and specifically the `Parquet` format were leveraged heavily to incrementally write the results to disk. The incremental writes of model coefficients allowed for minimal impact on in-memory processing. In addition, the columnar nature as well as the efficient IO operations enabled by the `Arrow` project allowed for inference to be performed on the model as a product of training as opposed to designing additional training steps solely for inference purposes. For more information on the `Arrow` project or the `Parquet` format as utilized in the `ann_inference` package please see either the `pyarrow` documentation: [pyarrow](https://arrow.apache.org/docs/python/) or the `Arrow` homepage: [Apache Arrow](https://arrow.apache.org/).\n",
    "\n",
    "Parquet files on disk can be read into a variety of powerful analytic engines including: `Spark`, `Drill`, and `Pandas DataFrames`. I will focus on Pandas as the files I will be working with are written on local disk but they could just have easily been added to hdfs or similar and processed.\n",
    "\n",
    "Reading files into memory in the form of a `DataFrame` is as simple as calling `read_parquet_store(path, nthreads=5)` on a directory where the `fit` or `gen_test_datasets` methods have been pointed to. Note that in addition to the path users can specify the number of threads to use when reading in the table which can significantly improve IO speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Model Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../parquet_store/regression_tests/12_10_2018/'\n",
    "weight_1 = 'stat=weight_1/'\n",
    "weight_2 = 'stat=weight_2/'\n",
    "\n",
    "pd_weight1 = ah.read_parquet_store(path + weight_1)\n",
    "pd_weight2 = ah.read_parquet_store(path + weight_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>epoch_num</th>\n",
       "      <th>weight_0</th>\n",
       "      <th>weight_1</th>\n",
       "      <th>weight_2</th>\n",
       "      <th>weight_3</th>\n",
       "      <th>weight_4</th>\n",
       "      <th>weight_5</th>\n",
       "      <th>weight_6</th>\n",
       "      <th>weight_7</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_14</th>\n",
       "      <th>weight_15</th>\n",
       "      <th>weight_16</th>\n",
       "      <th>weight_17</th>\n",
       "      <th>weight_18</th>\n",
       "      <th>weight_19</th>\n",
       "      <th>weight_20</th>\n",
       "      <th>weight_21</th>\n",
       "      <th>weight_22</th>\n",
       "      <th>weight_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153147</td>\n",
       "      <td>-0.126209</td>\n",
       "      <td>-0.132110</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.028346</td>\n",
       "      <td>-0.077215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097451</td>\n",
       "      <td>-0.187997</td>\n",
       "      <td>-0.005733</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>0.042605</td>\n",
       "      <td>-0.066392</td>\n",
       "      <td>-0.062436</td>\n",
       "      <td>-0.087700</td>\n",
       "      <td>-0.105640</td>\n",
       "      <td>-0.116440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131952</td>\n",
       "      <td>-0.158426</td>\n",
       "      <td>-0.157724</td>\n",
       "      <td>-0.074026</td>\n",
       "      <td>-0.052168</td>\n",
       "      <td>-0.039927</td>\n",
       "      <td>-0.023318</td>\n",
       "      <td>-0.080796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124718</td>\n",
       "      <td>-0.255012</td>\n",
       "      <td>-0.048592</td>\n",
       "      <td>0.046542</td>\n",
       "      <td>0.081661</td>\n",
       "      <td>-0.123948</td>\n",
       "      <td>-0.081646</td>\n",
       "      <td>-0.111682</td>\n",
       "      <td>-0.131240</td>\n",
       "      <td>-0.157065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117809</td>\n",
       "      <td>-0.195579</td>\n",
       "      <td>-0.192370</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>-0.082608</td>\n",
       "      <td>-0.041520</td>\n",
       "      <td>-0.017455</td>\n",
       "      <td>-0.091492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163322</td>\n",
       "      <td>-0.341930</td>\n",
       "      <td>-0.096185</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.137005</td>\n",
       "      <td>-0.197472</td>\n",
       "      <td>-0.108431</td>\n",
       "      <td>-0.140442</td>\n",
       "      <td>-0.166427</td>\n",
       "      <td>-0.205123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>-0.243649</td>\n",
       "      <td>-0.240786</td>\n",
       "      <td>-0.069228</td>\n",
       "      <td>-0.119489</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>-0.109658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219111</td>\n",
       "      <td>-0.465741</td>\n",
       "      <td>-0.155142</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.210659</td>\n",
       "      <td>-0.298616</td>\n",
       "      <td>-0.145001</td>\n",
       "      <td>-0.176622</td>\n",
       "      <td>-0.217103</td>\n",
       "      <td>-0.269640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111376</td>\n",
       "      <td>-0.303762</td>\n",
       "      <td>-0.303806</td>\n",
       "      <td>-0.073960</td>\n",
       "      <td>-0.164338</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>-0.136631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293065</td>\n",
       "      <td>-0.628758</td>\n",
       "      <td>-0.229522</td>\n",
       "      <td>-0.002121</td>\n",
       "      <td>0.308399</td>\n",
       "      <td>-0.431041</td>\n",
       "      <td>-0.192612</td>\n",
       "      <td>-0.221698</td>\n",
       "      <td>-0.284320</td>\n",
       "      <td>-0.350813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  epoch_num  weight_0  weight_1  weight_2  weight_3  weight_4  weight_5  \\\n",
       "0  16          0  0.153147 -0.126209 -0.132110 -0.085031 -0.024526 -0.039057   \n",
       "1  16          1  0.131952 -0.158426 -0.157724 -0.074026 -0.052168 -0.039927   \n",
       "2  16          2  0.117809 -0.195579 -0.192370 -0.068966 -0.082608 -0.041520   \n",
       "3  16          3  0.111538 -0.243649 -0.240786 -0.069228 -0.119489 -0.043892   \n",
       "4  16          4  0.111376 -0.303762 -0.303806 -0.073960 -0.164338 -0.047189   \n",
       "\n",
       "   weight_6  weight_7    ...      weight_14  weight_15  weight_16  weight_17  \\\n",
       "0 -0.028346 -0.077215    ...      -0.097451  -0.187997  -0.005733   0.066171   \n",
       "1 -0.023318 -0.080796    ...      -0.124718  -0.255012  -0.048592   0.046542   \n",
       "2 -0.017455 -0.091492    ...      -0.163322  -0.341930  -0.096185   0.029333   \n",
       "3 -0.010472 -0.109658    ...      -0.219111  -0.465741  -0.155142   0.013179   \n",
       "4 -0.001671 -0.136631    ...      -0.293065  -0.628758  -0.229522  -0.002121   \n",
       "\n",
       "   weight_18  weight_19  weight_20  weight_21  weight_22  weight_23  \n",
       "0   0.042605  -0.066392  -0.062436  -0.087700  -0.105640  -0.116440  \n",
       "1   0.081661  -0.123948  -0.081646  -0.111682  -0.131240  -0.157065  \n",
       "2   0.137005  -0.197472  -0.108431  -0.140442  -0.166427  -0.205123  \n",
       "3   0.210659  -0.298616  -0.145001  -0.176622  -0.217103  -0.269640  \n",
       "4   0.308399  -0.431041  -0.192612  -0.221698  -0.284320  -0.350813  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_weight1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(pd_weight1.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that approximately 20 tests were run across the network. The number of observations is sufficient that we should be able to generate insight into the underlying behavior of the network at each epoch. I will focus most of my testing on the final epoch which we can easily see by calling the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_weight1.epoch_num.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll generate a `DataFrame` consisting of the final epoch across all tests to better understand the behavior of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch = pd_weight1[pd_weight1.epoch_num==pd_weight1.epoch_num.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>epoch_num</th>\n",
       "      <th>weight_0</th>\n",
       "      <th>weight_1</th>\n",
       "      <th>weight_2</th>\n",
       "      <th>weight_3</th>\n",
       "      <th>weight_4</th>\n",
       "      <th>weight_5</th>\n",
       "      <th>weight_6</th>\n",
       "      <th>weight_7</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_14</th>\n",
       "      <th>weight_15</th>\n",
       "      <th>weight_16</th>\n",
       "      <th>weight_17</th>\n",
       "      <th>weight_18</th>\n",
       "      <th>weight_19</th>\n",
       "      <th>weight_20</th>\n",
       "      <th>weight_21</th>\n",
       "      <th>weight_22</th>\n",
       "      <th>weight_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>16</td>\n",
       "      <td>499</td>\n",
       "      <td>0.201233</td>\n",
       "      <td>-0.835866</td>\n",
       "      <td>-0.874425</td>\n",
       "      <td>-0.158132</td>\n",
       "      <td>-0.524150</td>\n",
       "      <td>-0.077423</td>\n",
       "      <td>0.090815</td>\n",
       "      <td>-0.384275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.935509</td>\n",
       "      <td>-1.916772</td>\n",
       "      <td>-0.791782</td>\n",
       "      <td>-0.100906</td>\n",
       "      <td>1.174086</td>\n",
       "      <td>-1.373693</td>\n",
       "      <td>-0.604935</td>\n",
       "      <td>-0.624108</td>\n",
       "      <td>-0.870084</td>\n",
       "      <td>-1.059503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>9</td>\n",
       "      <td>499</td>\n",
       "      <td>-1.062302</td>\n",
       "      <td>-2.102915</td>\n",
       "      <td>1.079005</td>\n",
       "      <td>1.171164</td>\n",
       "      <td>-1.760090</td>\n",
       "      <td>-0.581174</td>\n",
       "      <td>0.058283</td>\n",
       "      <td>-0.259657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738824</td>\n",
       "      <td>-0.568595</td>\n",
       "      <td>-0.415622</td>\n",
       "      <td>1.070731</td>\n",
       "      <td>-0.326788</td>\n",
       "      <td>0.778210</td>\n",
       "      <td>0.722915</td>\n",
       "      <td>1.278344</td>\n",
       "      <td>-0.014618</td>\n",
       "      <td>0.696556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5</td>\n",
       "      <td>499</td>\n",
       "      <td>-0.370249</td>\n",
       "      <td>-1.120461</td>\n",
       "      <td>0.063580</td>\n",
       "      <td>1.848145</td>\n",
       "      <td>-0.923493</td>\n",
       "      <td>1.308507</td>\n",
       "      <td>-1.361168</td>\n",
       "      <td>0.971585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914235</td>\n",
       "      <td>0.141300</td>\n",
       "      <td>-1.529189</td>\n",
       "      <td>0.409931</td>\n",
       "      <td>-0.396385</td>\n",
       "      <td>-0.731094</td>\n",
       "      <td>-0.719019</td>\n",
       "      <td>0.898097</td>\n",
       "      <td>-1.456085</td>\n",
       "      <td>-1.187489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6</td>\n",
       "      <td>499</td>\n",
       "      <td>-0.759901</td>\n",
       "      <td>-1.279169</td>\n",
       "      <td>-0.966193</td>\n",
       "      <td>-0.967113</td>\n",
       "      <td>1.525814</td>\n",
       "      <td>-0.709766</td>\n",
       "      <td>-0.241096</td>\n",
       "      <td>2.157200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042159</td>\n",
       "      <td>0.221722</td>\n",
       "      <td>-0.393608</td>\n",
       "      <td>0.784048</td>\n",
       "      <td>0.048170</td>\n",
       "      <td>-0.428956</td>\n",
       "      <td>1.740542</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>-1.565762</td>\n",
       "      <td>-0.893277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>11</td>\n",
       "      <td>499</td>\n",
       "      <td>-0.221015</td>\n",
       "      <td>1.472480</td>\n",
       "      <td>-0.205944</td>\n",
       "      <td>1.075796</td>\n",
       "      <td>-0.751765</td>\n",
       "      <td>-0.289074</td>\n",
       "      <td>-1.841523</td>\n",
       "      <td>-0.259432</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.207510</td>\n",
       "      <td>0.296129</td>\n",
       "      <td>0.256003</td>\n",
       "      <td>-0.007186</td>\n",
       "      <td>1.977217</td>\n",
       "      <td>-0.270711</td>\n",
       "      <td>-0.961067</td>\n",
       "      <td>-0.054156</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>-1.977958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  epoch_num  weight_0  weight_1  weight_2  weight_3  weight_4  \\\n",
       "499  16        499  0.201233 -0.835866 -0.874425 -0.158132 -0.524150   \n",
       "499   9        499 -1.062302 -2.102915  1.079005  1.171164 -1.760090   \n",
       "499   5        499 -0.370249 -1.120461  0.063580  1.848145 -0.923493   \n",
       "499   6        499 -0.759901 -1.279169 -0.966193 -0.967113  1.525814   \n",
       "499  11        499 -0.221015  1.472480 -0.205944  1.075796 -0.751765   \n",
       "\n",
       "     weight_5  weight_6  weight_7    ...      weight_14  weight_15  weight_16  \\\n",
       "499 -0.077423  0.090815 -0.384275    ...      -0.935509  -1.916772  -0.791782   \n",
       "499 -0.581174  0.058283 -0.259657    ...       0.738824  -0.568595  -0.415622   \n",
       "499  1.308507 -1.361168  0.971585    ...       0.914235   0.141300  -1.529189   \n",
       "499 -0.709766 -0.241096  2.157200    ...      -0.042159   0.221722  -0.393608   \n",
       "499 -0.289074 -1.841523 -0.259432    ...      -1.207510   0.296129   0.256003   \n",
       "\n",
       "     weight_17  weight_18  weight_19  weight_20  weight_21  weight_22  \\\n",
       "499  -0.100906   1.174086  -1.373693  -0.604935  -0.624108  -0.870084   \n",
       "499   1.070731  -0.326788   0.778210   0.722915   1.278344  -0.014618   \n",
       "499   0.409931  -0.396385  -0.731094  -0.719019   0.898097  -1.456085   \n",
       "499   0.784048   0.048170  -0.428956   1.740542   0.053566  -1.565762   \n",
       "499  -0.007186   1.977217  -0.270711  -0.961067  -0.054156   0.085387   \n",
       "\n",
       "     weight_23  \n",
       "499  -1.059503  \n",
       "499   0.696556  \n",
       "499  -1.187489  \n",
       "499  -0.893277  \n",
       "499  -1.977958  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_epoch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Weights\n",
    "\n",
    "Next, the weights will be converted into a __Numpy__ `ndarray` to allow bootstrap estimates of the mean and variance for the given weight to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weight1 = final_epoch[final_epoch.columns[2:]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform inference we need a mechanism to gather evidence about the population of interest, in this case model parameters. To do this we will leverage the percentile bootstrap for both population mean and variance over the 20 iterations of `fit`. \n",
    "\n",
    "Methods for calling the percentile bootstrap can be found in `boot.py` and specifically the `boot_stat` method. For efficiency space is preallocated before assignment for the bootstrap estimates of the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_samples = 999\n",
    "\n",
    "boot_mean = np.zeros([999, np_weight1.shape[1]])\n",
    "boot_var = np.zeros([999, np_weight1.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Estimates\n",
    "\n",
    "Next, we iterate over the columns in the matrices for storing the test statistics and assign the results from `boot_stat` to each of the columns in `boot_mean` and `boot_var`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(0, boot_mean.shape[1]):\n",
    "    boot_mean[:, j] = boot.boot_stat(np_weight1[:, j],n_iter=boot_samples, test_stat=np.mean)\n",
    "    boot_var[:, j] = boot.boot_stat(np_weight1[:, j],n_iter=boot_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_percentile = np.percentile(boot_mean, [2.5, 97.5], axis=0)\n",
    "var_percentile = np.percentile(boot_var, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60863896, -0.63390006, -0.14211912, -0.48261435, -0.37338985,\n",
       "        -0.51312214, -0.24127065, -0.11964323, -0.03336317, -0.19826915,\n",
       "        -0.49223615, -0.2062193 , -0.22223069, -0.67167453, -0.48060458,\n",
       "        -0.97919293, -0.36363286, -0.5822899 , -0.47663615, -0.5245289 ,\n",
       "        -0.33241502, -0.34337184, -0.30713816, -0.67530673],\n",
       "       [ 0.33820585,  0.15343776,  0.51168096,  0.39903315,  0.37298373,\n",
       "         0.44242845,  0.57032879,  0.75579374,  0.65474487,  0.68490494,\n",
       "         0.39930756,  0.6431668 ,  0.51481378,  0.1699546 ,  0.34637595,\n",
       "        -0.06245877,  0.35283299,  0.48915329,  0.29666465,  0.28400799,\n",
       "         0.5226631 ,  0.40590285,  0.37095594,  0.15789228]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we focus our attention on individual parameters we are able to see their behavior from the first to final epoch. We begin by selecting a parameter to review and calculcating the variance at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_weight0 = pd_weight1[pd_weight1.columns[0:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we again preallocate space for the bootstrap samples and assign to them for each epoch in the pandas array. We will then pull empirical confidence intervals for the given observations and plot them over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0_np = np.zeros([boot_samples, len(pd_weight0.epoch_num.unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(0, weight0_np.shape[1]):\n",
    "    weight0_np[:,j] = boot.boot_stat(pd_weight0[pd_weight0.epoch_num==j].weight_0.values, n_iter=boot_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_var_weight = np.percentile(weight0_np, [2.5, 50, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, boot_var_weight.shape[1], 50), boot_var_weight[1,np.arange(0, boot_var_weight.shape[1], 50)], 'b--o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above that the variance is on a slight upward trajectory. This is a bit surprising because we would expect the variance to have stabilized more. However, the variance is so low in the estimates generally that it is not a large concern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
